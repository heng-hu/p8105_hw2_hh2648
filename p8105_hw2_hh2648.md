P8105 Data Science I - Homework 2
================
Heng Hu (hh2648)
2025-09-30

Load packages

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

``` r
# Input and clean pols-month.csv
pols = read_csv(file = "./data/pols-month.csv") |> 
  separate(mon, c("year", "month", "day"), remove = FALSE) |> 
  mutate(year = as.numeric(year),
         month = month(mon, label = TRUE, abbr = FALSE),
         president = ifelse(prez_gop == 1, "rep", "dem")) |> 
  select(-c(mon, day, prez_gop, prez_dem)) |> 
  select(year, month, president, everything()) |> 
  arrange(year, month)


# Input and clean snp.csv
snp = read_csv(file = "./data/snp.csv") |> 
  mutate(date = as.Date(date, format = "%m/%d/%y"),
         year = year(date),
         year = ifelse(year > 2025, year - 100, year),
         month = month(date, label = TRUE, abbr = FALSE)) |> 
  select(year, month, close) |> 
  arrange(year, month)


# Input and clean unemployment.csv
unemployment = read_csv(file = "./data/unemployment.csv") |> 
  pivot_longer(cols = (-Year),
               names_to = "month_abb",
               values_to = "ue_rate") |> 
  mutate(year = Year,
         month = match(month_abb, month.abb),
         yr_mon = as.Date(paste(year, month, "01", sep = "-")),
         month = month(yr_mon, label = TRUE, abbr = FALSE)) |> 
  select(year, month, ue_rate) |> 
  arrange(year, month)


# Join the 3 datasets 
full_dt = pols |> 
  left_join(snp, by = c("year", "month")) |> 
  left_join(unemployment, by = c("year", "month"))

full_dt
```

    ## # A tibble: 822 × 11
    ##     year month   president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <dbl> <ord>   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January dem            23      51     253      23      45     198    NA
    ##  2  1947 Februa… dem            23      51     253      23      45     198    NA
    ##  3  1947 March   dem            23      51     253      23      45     198    NA
    ##  4  1947 April   dem            23      51     253      23      45     198    NA
    ##  5  1947 May     dem            23      51     253      23      45     198    NA
    ##  6  1947 June    dem            23      51     253      23      45     198    NA
    ##  7  1947 July    dem            23      51     253      23      45     198    NA
    ##  8  1947 August  dem            23      51     253      23      45     198    NA
    ##  9  1947 Septem… dem            23      51     253      23      45     198    NA
    ## 10  1947 October dem            23      51     253      23      45     198    NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: ue_rate <dbl>

The dataset `pols` has `9` variables and `822` records, and covers the
period from `January`, `1947` to `June`, `2015`. The dataset `snp` has
`3` variables and `787` records, and covers the period from `January`,
`1950` to `July`, `2015`. The dataset `unemployment` has `3` variables
and `816` observations recording the unemployment rate, and covers the
period from `January`, `1948` to `December`, `2015`. All of them have
variables `year` and `month`, which indicate the time period. In
addition, the dataset `pols` has `president` which indicates the
political party of the president during that time and some other
variables related to the number of national politicians who are
Democratic or Republican. The dataset `snp` has `close` recording the
closing values of the S&P stock index on the associated date. The
dataset `unemployment` has `ue_rate` representing the unemployment rate
during that time.

Since the merged data may be used to analyze the political influence on
national-level economic conditions, I applied `left_join` to retain all
the observations from the `pols` dataset when merging these 3 datasets.
The merged dataset is called `full_dt`. It contains `822` observations
and includes all variables from the original datasets, totaling `11`
variables, and covers the period from `January`, `1947` to `June`,
`2015`.

## Problem 2

``` r
# Read and clean the Mr. Trash Wheel sheet
mr_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Mr. Trash Wheel",
                      range = cell_cols("A:N"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.numeric(year),
         sports_balls = as.integer(round(sports_balls, 0)),
         wheel_name = "Mr. Trash Wheel") |> 
  select(wheel_name, everything())


# Read and clean the Professor Trash Wheel sheet
prof_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Professor Trash Wheel",
                      range = cell_cols("A:M"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel_name = "Professor Trash Wheel") |> 
  select(wheel_name, everything())


# Read and clean the Gwynns Falls Trash Wheel sheet
gwynns_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Gwynns Falls Trash Wheel",
                      range = cell_cols("A:L"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel_name = "Gwynns Falls Trash Wheel") |> 
  select(wheel_name, everything())


# Combine these datasets
three_trash_wheel = bind_rows(mr_trash, prof_trash, gwynns_trash)

three_trash_wheel
```

    ## # A tibble: 1,188 × 15
    ##    wheel_name      dumpster month  year date                weight_tons
    ##    <chr>              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 1,178 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

The dataset `mr_trash` has `15` variables and `707` records, with a time
span ranging from `May`, `2014` to `July`, `2025`. The dataset
`prof_trash` has `14` variables and `132` records, with a time span
ranging from `January`, `2017` to `July`, `2025`. The dataset
`gwynns_trash` has `13` variables and `349` records, with a time span
ranging from `July`, `2021` to `July`, `2025`. All of them share some
common variables listed here. The `wheel_name` indicate the name of
trash wheel. `year`, `month`, and `date` represent the time period.
`weight_tons` and `volume_cubic_yards` are the total weight and volume
of trash that the trash wheel collected. `homes_powered` shows the
number of homes powered by the energy generated from burning collected
trash. Other variables like
`plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls`
show the count numbers of different types of trash. However, not all of
them are present in every dataset.

The combined dataset `three_trash_wheel` has `15` variables and `1188`
records. It contains data collected from
`Mr. Trash Wheel, Professor Trash Wheel, Gwynns Falls Trash Wheel` and
all the variables listed in previous paragraph.

Based on the current data, the total weight of trash collected by
Professor Trash Wheel is `282.26` tons. The total number of cigarette
butts collected by Gwynnda in June of 2022 was `18120`.

## Problem 3

``` r
# Read and clean data
rent = read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  pivot_longer(cols = (starts_with("20")),
               names_to = "rent_date",
               values_to = "rent_price") |> 
  janitor::clean_names() |> 
  filter(!is.na(rent_price)) |> 
  rename(zip_code = region_name) |> 
  separate(rent_date, c(paste0("rent_", c("year", "month", "day"))), remove = FALSE) |> 
  mutate(county = trimws(gsub("County", "", county_name)),
         rent_year = as.integer(rent_year),
         rent_month = as.integer(rent_month),
         rent_day = as.integer(rent_day),
         rent_date = as.Date(rent_date)) |> 
  select(-county_name)

zip = read_csv("./data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(zip_file_date = as.Date(file_date, format = "%m/%d/%y")) |> 
  select(-file_date)


# Merge two datasets and tidy
full_rent = rent |> 
  left_join(zip, by = c("zip_code", "county")) |> 
  select(region_id, size_rank, region_type, zip_code, zip_file_date, state_name, state, state_fips, city, metro, county, county_code, county_fips, neighborhood, everything()) |> 
  arrange()

full_rent
```

    ## # A tibble: 10,450 × 19
    ##    region_id size_rank region_type zip_code zip_file_date state_name state
    ##        <dbl>     <dbl> <chr>          <dbl> <date>        <chr>      <chr>
    ##  1     62080         4 zip            11368 2007-07-25    NY         NY   
    ##  2     62080         4 zip            11368 2007-07-25    NY         NY   
    ##  3     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  4     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  5     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  6     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  7     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  8     62093         7 zip            11385 2007-07-25    NY         NY   
    ##  9     62093         7 zip            11385 2007-07-25    NY         NY   
    ## 10     62093         7 zip            11385 2007-07-25    NY         NY   
    ## # ℹ 10,440 more rows
    ## # ℹ 12 more variables: state_fips <dbl>, city <chr>, metro <chr>, county <chr>,
    ## #   county_code <chr>, county_fips <dbl>, neighborhood <chr>, rent_date <date>,
    ## #   rent_year <int>, rent_month <int>, rent_day <int>, rent_price <dbl>

The dataset `full_rent` has `19` variables and `10450` observations. It
contains rental prices in New York City from `2015/1` to `2024/8`. It
contains `149` unique ZIP codes and `43` unique neighborhoods.

``` r
# Find ZIP code not listed in full_rent
zip_w_rent = full_rent |> 
  select(zip_code)

zip_wo_rent = zip |> 
  anti_join(zip_w_rent, by = "zip_code")

zip_wo_rent |> 
  select(neighborhood) |> 
  table(useNA = c("always")) |> 
  sort(decreasing = TRUE)
```

    ## neighborhood
    ##                       <NA>           Southeast Queens 
    ##                        137                          8 
    ##           Southwest Queens                    Jamaica 
    ##                          6                          4 
    ##                  Rockaways           Northeast Queens 
    ##                          3                          2 
    ##              Port Richmond                South Shore 
    ##                          2                          2 
    ##     Canarsie and Flatlands        Chelsea and Clinton 
    ##                          1                          1 
    ## Hunts Point and Mott Haven               North Queens 
    ##                          1                          1 
    ##            Northeast Bronx            Southeast Bronx 
    ##                          1                          1 
    ##          Southern Brooklyn 
    ##                          1

The dataset `zip_wo_rent` was created to include all the ZIP codes
without any rental observations. After examining `neighborhood` count
numbers in this dataset, we found most of them don’t have associated
`neighborhood` information, suggesting they may be reserved for future
ZIP code expansion.

``` r
# Compare rental prices in January 2021 to prices in January 2020
rent_drop = full_rent |> 
  filter(rent_year %in% c(2020, 2021) & rent_month == 1) |> 
  pivot_wider(id_cols = c(zip_code, county, neighborhood),
              names_from = rent_year,
              values_from = rent_price,
              names_prefix = "rent_") |> 
  mutate(rent_drop = rent_2020 - rent_2021) |> 
  filter(!is.na(rent_drop)) |> 
  arrange(desc(rent_2020)) |> 
  mutate(rent_rank = row_number()) |> 
  arrange(desc(rent_drop))

rent_drop_10 = rent_drop |>
  head(10)

rent_drop_10
```

    ## # A tibble: 10 × 7
    ##    zip_code county   neighborhood        rent_2020 rent_2021 rent_drop rent_rank
    ##       <dbl> <chr>    <chr>                   <dbl>     <dbl>     <dbl>     <int>
    ##  1    10007 New York Lower Manhattan         6334.     5422.      913.         1
    ##  2    10069 New York <NA>                    4623.     3875.      748.         2
    ##  3    10009 New York Lower East Side         3406.     2692.      714.        23
    ##  4    10016 New York Gramercy Park and …     3731.     3019.      712.         9
    ##  5    10001 New York Chelsea and Clinton     4108.     3398.      710.         4
    ##  6    10002 New York Lower East Side         3645.     2935.      710.        11
    ##  7    10004 New York Lower Manhattan         3150.     2444.      706.        32
    ##  8    10038 New York Lower Manhattan         3573.     2876.      698.        14
    ##  9    10012 New York Greenwich Village …     3629.     2942.      686.        12
    ## 10    10010 New York Gramercy Park and …     3697.     3012.      685.        10

The dataset `rent_drop` was created to compare rental prices in January
2021 to prices in January 2020 for all available ZIP code. It contains
`82` records with valid rental price difference between the two time
points. The variable `rent_drop` stores the calculated difference, while
`rent_rank` represents the rank of rental prices from highest to lowest
in January 2020.

The dataset `rent_drop_10` lists the 10 ZIP codes with largest drop in
price from January 2020 to January 2021. All of them are from `New York`
County. Most of them also ranked among the top rental prices in January
2020 base on `rent_rank`.
