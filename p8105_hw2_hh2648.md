P8105 Data Science I - Homework 2
================
Heng Hu (hh2648)
2025-09-30

Load packages

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

``` r
# Input and clean pols-month.csv
pols = read_csv(file = "./data/pols-month.csv") |> 
  separate(mon, c("year", "month", "day"), remove = FALSE) |> 
  mutate(year = as.numeric(year),
         month = month(mon, label = TRUE, abbr = FALSE),
         president = ifelse(prez_gop == 1, "rep", "dem")) |> 
  select(-c(mon, day, prez_gop, prez_dem)) |> 
  select(year, month, president, everything()) |> 
  arrange(year, month)

pols
```

    ## # A tibble: 822 × 9
    ##     year month     president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <dbl> <ord>     <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January   dem            23      51     253      23      45     198
    ##  2  1947 February  dem            23      51     253      23      45     198
    ##  3  1947 March     dem            23      51     253      23      45     198
    ##  4  1947 April     dem            23      51     253      23      45     198
    ##  5  1947 May       dem            23      51     253      23      45     198
    ##  6  1947 June      dem            23      51     253      23      45     198
    ##  7  1947 July      dem            23      51     253      23      45     198
    ##  8  1947 August    dem            23      51     253      23      45     198
    ##  9  1947 September dem            23      51     253      23      45     198
    ## 10  1947 October   dem            23      51     253      23      45     198
    ## # ℹ 812 more rows

The dataset `pols` has `9` variables and `822` records related to the
number of national politicians who are democratic or republican. The
dataset covers the period from `January`, `1947` to `June`, `2015`.
Variables `year` and `month` represent the time period, while
`president` indicates the political party of the president during that
time.

``` r
# Input and clean snp.csv
snp = read_csv(file = "./data/snp.csv") |> 
  mutate(date = as.Date(date, format = "%m/%d/%y"),
         year = year(date),
         year = ifelse(year > 2025, year-100, year),
         month = month(date, label = TRUE, abbr = FALSE)) |> 
  select(year, month, close) |> 
  arrange(year, month)

snp
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <dbl> <ord>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # ℹ 777 more rows

The dataset `snp` has `3` variables and `787` records related to
Standard & Poor’s stock market index (S&P). The dataset covers the
period from `January`, `1950` to `July`, `2015`. Variables `year` and
`month` represent the time period, while `close` indicates the closing
values of the S&P stock index on the associated date.

``` r
# Input and clean unemployment.csv
unemployment = read_csv(file = "./data/unemployment.csv") |> 
  pivot_longer(cols = (-Year),
               names_to = "month_abb",
               values_to = "ue_rate") |> 
  mutate(year = Year,
         month = match(month_abb, month.abb),
         yr_mon = as.Date(paste(year, month, "01", sep = "-")),
         month = month(yr_mon, label = TRUE, abbr = FALSE)) |> 
  select(year, month, ue_rate) |> 
  arrange(year, month)

unemployment
```

    ## # A tibble: 816 × 3
    ##     year month     ue_rate
    ##    <dbl> <ord>       <dbl>
    ##  1  1948 January       3.4
    ##  2  1948 February      3.8
    ##  3  1948 March         4  
    ##  4  1948 April         3.9
    ##  5  1948 May           3.5
    ##  6  1948 June          3.6
    ##  7  1948 July          3.6
    ##  8  1948 August        3.9
    ##  9  1948 September     3.8
    ## 10  1948 October       3.7
    ## # ℹ 806 more rows

The dataset `unemployment` has `3` variables and `816` observations
recording the unemployment rate. The dataset covers the period from
`January`, `1948` to `December`, `2015`. Variables `year` and `month`
represent the time period, while `ue_rate` indicates the unemployment
rate during that time.

``` r
# Join the 3 datasets 
full_dt = pols |> 
  left_join(snp, by = c("year", "month")) |> 
  left_join(unemployment, by = c("year", "month"))

full_dt
```

    ## # A tibble: 822 × 11
    ##     year month   president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <dbl> <ord>   <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 January dem            23      51     253      23      45     198    NA
    ##  2  1947 Februa… dem            23      51     253      23      45     198    NA
    ##  3  1947 March   dem            23      51     253      23      45     198    NA
    ##  4  1947 April   dem            23      51     253      23      45     198    NA
    ##  5  1947 May     dem            23      51     253      23      45     198    NA
    ##  6  1947 June    dem            23      51     253      23      45     198    NA
    ##  7  1947 July    dem            23      51     253      23      45     198    NA
    ##  8  1947 August  dem            23      51     253      23      45     198    NA
    ##  9  1947 Septem… dem            23      51     253      23      45     198    NA
    ## 10  1947 October dem            23      51     253      23      45     198    NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: ue_rate <dbl>

Since the merged data may be used to analyze the political influence on
national-level economic conditions, I applied `left_join` to retain all
the observations from the `pols` dataset when merging these 3 datasets.
The merged dataset is called `full_dt`. It contains `822` observations
of `11` variables, and covers the period from `January`, `1947` to
`June`, `2015`. Like the previous datasets, variables `year` and `month`
represent the time period. `president`, `close`, and `ue_rate` indicate,
respectively, the political party of the president, the closing values
of the S&P stock index, and unemployment rate during that time.

## Problem 2

``` r
# Read and clean the Mr. Trash Wheel sheet
mr_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Mr. Trash Wheel",
                      range = cell_cols("A:N"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.numeric(year),
         sports_balls = as.integer(round(sports_balls, 0)),
         wheel_name = "Mr. Trash Wheel") |> 
  select(wheel_name, everything())
mr_trash
```

    ## # A tibble: 707 × 15
    ##    wheel_name      dumpster month  year date                weight_tons
    ##    <chr>              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 697 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
# Read and clean the Professor Trash Wheel sheet
prof_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Professor Trash Wheel",
                      range = cell_cols("A:M"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel_name = "Professor Trash Wheel") |> 
  select(wheel_name, everything())

prof_trash
```

    ## # A tibble: 132 × 14
    ##    wheel_name            dumpster month     year date                weight_tons
    ##    <chr>                    <dbl> <chr>    <dbl> <dttm>                    <dbl>
    ##  1 Professor Trash Wheel        1 January   2017 2017-01-02 00:00:00        1.79
    ##  2 Professor Trash Wheel        2 January   2017 2017-01-30 00:00:00        1.58
    ##  3 Professor Trash Wheel        3 February  2017 2017-02-26 00:00:00        2.32
    ##  4 Professor Trash Wheel        4 February  2017 2017-02-26 00:00:00        3.72
    ##  5 Professor Trash Wheel        5 February  2017 2017-02-28 00:00:00        1.45
    ##  6 Professor Trash Wheel        6 March     2017 2017-03-30 00:00:00        1.71
    ##  7 Professor Trash Wheel        7 April     2017 2017-04-01 00:00:00        1.82
    ##  8 Professor Trash Wheel        8 April     2017 2017-04-20 00:00:00        2.37
    ##  9 Professor Trash Wheel        9 May       2017 2017-05-10 00:00:00        2.64
    ## 10 Professor Trash Wheel       10 May       2017 2017-05-26 00:00:00        2.78
    ## # ℹ 122 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>

``` r
# Read and clean the Gwynns Falls Trash Wheel sheet
gwynns_trash = read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                      sheet = "Gwynns Falls Trash Wheel",
                      range = cell_cols("A:L"),
                      skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel_name = "Gwynns Falls Trash Wheel") |> 
  select(wheel_name, everything())

gwynns_trash
```

    ## # A tibble: 349 × 13
    ##    wheel_name               dumpster month  year date                weight_tons
    ##    <chr>                       <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Gwynns Falls Trash Wheel        1 July   2021 2021-07-03 00:00:00        0.93
    ##  2 Gwynns Falls Trash Wheel        2 July   2021 2021-07-07 00:00:00        2.26
    ##  3 Gwynns Falls Trash Wheel        3 July   2021 2021-07-07 00:00:00        1.62
    ##  4 Gwynns Falls Trash Wheel        4 July   2021 2021-07-16 00:00:00        1.76
    ##  5 Gwynns Falls Trash Wheel        5 July   2021 2021-07-30 00:00:00        1.53
    ##  6 Gwynns Falls Trash Wheel        6 Augu…  2021 2021-08-11 00:00:00        2.06
    ##  7 Gwynns Falls Trash Wheel        7 Augu…  2021 2021-08-14 00:00:00        1.9 
    ##  8 Gwynns Falls Trash Wheel        8 Augu…  2021 2021-08-16 00:00:00        2.16
    ##  9 Gwynns Falls Trash Wheel        9 Augu…  2021 2021-08-16 00:00:00        2.6 
    ## 10 Gwynns Falls Trash Wheel       10 Augu…  2021 2021-08-17 00:00:00        3.21
    ## # ℹ 339 more rows
    ## # ℹ 7 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
# Combine these datasets
three_trash_wheel = bind_rows(mr_trash, prof_trash, gwynns_trash)

three_trash_wheel
```

    ## # A tibble: 1,188 × 15
    ##    wheel_name      dumpster month  year date                weight_tons
    ##    <chr>              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 1,178 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

The dataset `mr_trash` has `15` variables and `707` records, with a time
span ranging from `May`, `2014` to `July`, `2025`. The dataset
`prof_trash` has `14` variables and `132` records, with a time span
ranging from `January`, `2017` to `July`, `2025`. The dataset
`gwynns_trash` has `13` variables and `349` records, with a time span
ranging from `July`, `2021` to `July`, `2025`. All of them share some
common variables listed here. The `wheel_name` indicate the name of
trash wheel. `year`, `month`, and `date` represent the time period.
`weight_tons` and `volume_cubic_yards` are the total weight and volume
of trash that the trash wheel collected. `homes_powered` shows the
number of homes powered by the energy generated from burning collected
trash. Other variables like
`plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls`
show the count numbers of different types of trash. However, not all of
them are present in every dataset.

The combined dataset `three_trash_wheel` has `15` variables and `1188`
records. It contains data collected from
`Mr. Trash Wheel, Professor Trash Wheel, Gwynns Falls Trash Wheel` and
all the variables listed in previous paragraph.

Based on the current data, the total weight of trash collected by
Professor Trash Wheel is `282.26` tons. The total number of cigarette
butts collected by Gwynnda in June of 2022 was `18120`.

## Problem 3

``` r
# Read and clean data
rent = read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  pivot_longer(cols = (starts_with("20")),
               names_to = "rent_date",
               values_to = "rent_price") |> 
  janitor::clean_names() |> 
  filter(!is.na(rent_price)) |> 
  rename(zip_code = region_name) |> 
  separate(rent_date, c(paste0("rent_", c("year", "month", "day"))), remove = FALSE) |> 
  mutate(county = trimws(gsub("County", "", county_name)),
         rent_year = as.integer(rent_year),
         rent_month = as.integer(rent_month),
         rent_day = as.integer(rent_day)) |> 
  select(-county_name)

zip = read_csv("./data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  rename(zip_file_date = file_date)

# Merge two datasets and tidy
full_rent = rent |> 
  left_join(zip, by = c("zip_code", "county")) |> 
  select(region_id, size_rank, region_type, zip_code, zip_file_date, state_name, state, state_fips, city, metro, county, county_code, county_fips, neighborhood, everything()) |> 
  arrange()

full_rent
```

    ## # A tibble: 10,450 × 19
    ##    region_id size_rank region_type zip_code zip_file_date state_name state
    ##        <dbl>     <dbl> <chr>          <dbl> <chr>         <chr>      <chr>
    ##  1     62080         4 zip            11368 7/25/07       NY         NY   
    ##  2     62080         4 zip            11368 7/25/07       NY         NY   
    ##  3     62093         7 zip            11385 7/25/07       NY         NY   
    ##  4     62093         7 zip            11385 7/25/07       NY         NY   
    ##  5     62093         7 zip            11385 7/25/07       NY         NY   
    ##  6     62093         7 zip            11385 7/25/07       NY         NY   
    ##  7     62093         7 zip            11385 7/25/07       NY         NY   
    ##  8     62093         7 zip            11385 7/25/07       NY         NY   
    ##  9     62093         7 zip            11385 7/25/07       NY         NY   
    ## 10     62093         7 zip            11385 7/25/07       NY         NY   
    ## # ℹ 10,440 more rows
    ## # ℹ 12 more variables: state_fips <dbl>, city <chr>, metro <chr>, county <chr>,
    ## #   county_code <chr>, county_fips <dbl>, neighborhood <chr>, rent_date <chr>,
    ## #   rent_year <int>, rent_month <int>, rent_day <int>, rent_price <dbl>

The dataset `full_rent` has `19` variables and `10450` observations. It
contains rental prices in New York City from `2024/7` to `2024/8`. It
contains `149` unique ZIP codes and `0` unique neighborhoods.

``` r
# Find ZIP code not listed in full_rent
zip_w_rent = full_rent |> 
  select(zip_code)

zip_wo_rent = zip |> 
  anti_join(zip_w_rent, by = "zip_code")

zip_wo_rent
```

    ## # A tibble: 171 × 7
    ##    county state_fips county_code county_fips zip_code zip_file_date neighborhood
    ##    <chr>       <dbl> <chr>             <dbl>    <dbl> <chr>         <chr>       
    ##  1 Bronx          36 005               36005    10464 7/25/07       Southeast B…
    ##  2 Bronx          36 005               36005    10474 7/25/07       Hunts Point…
    ##  3 Bronx          36 005               36005    10475 7/25/07       Northeast B…
    ##  4 Bronx          36 005               36005    10499 7/25/07       <NA>        
    ##  5 Bronx          36 005               36005    10550 7/25/07       <NA>        
    ##  6 Bronx          36 005               36005    10704 7/25/07       <NA>        
    ##  7 Bronx          36 005               36005    10705 7/25/07       <NA>        
    ##  8 Bronx          36 005               36005    10803 7/25/07       <NA>        
    ##  9 Kings          36 047               36047    11202 7/25/07       <NA>        
    ## 10 Kings          36 047               36047    11224 7/25/07       Southern Br…
    ## # ℹ 161 more rows

``` r
zip_wo_rent |> 
  select(neighborhood) |> 
  table(useNA = c("always")) |> 
  sort(decreasing = TRUE)
```

    ## neighborhood
    ##                       <NA>           Southeast Queens 
    ##                        137                          8 
    ##           Southwest Queens                    Jamaica 
    ##                          6                          4 
    ##                  Rockaways           Northeast Queens 
    ##                          3                          2 
    ##              Port Richmond                South Shore 
    ##                          2                          2 
    ##     Canarsie and Flatlands        Chelsea and Clinton 
    ##                          1                          1 
    ## Hunts Point and Mott Haven               North Queens 
    ##                          1                          1 
    ##            Northeast Bronx            Southeast Bronx 
    ##                          1                          1 
    ##          Southern Brooklyn 
    ##                          1

The dataset `zip_wo_rent` was created to include all the ZIP codes
without any rental observations. After examining `neighborhood` count
numbers in this dataset, we found most of them don’t have associated
`neighborhood` information, suggesting they may be reserved for future
data expansion.

``` r
# Compare rental prices in January 2021 to prices in January 2020
rent_drop = full_rent |> 
  filter(rent_year %in% c(2020, 2021) & rent_month ==  1) |> 
  pivot_wider(id_cols = c(zip_code, county, neighborhood),
              names_from = rent_year,
              values_from = rent_price,
              names_prefix = "rent_") |> 
  mutate(rent_drop = rent_2020 - rent_2021) |> 
  filter(!is.na(rent_drop)) |> 
  arrange(desc(rent_2020)) |> 
  mutate(rent_rank = row_number()) |> 
  arrange(desc(rent_drop))

rent_drop_10 = rent_drop |>
  head(10)

rent_drop_10
```

    ## # A tibble: 10 × 7
    ##    zip_code county   neighborhood        rent_2020 rent_2021 rent_drop rent_rank
    ##       <dbl> <chr>    <chr>                   <dbl>     <dbl>     <dbl>     <int>
    ##  1    10007 New York Lower Manhattan         6334.     5422.      913.         1
    ##  2    10069 New York <NA>                    4623.     3875.      748.         2
    ##  3    10009 New York Lower East Side         3406.     2692.      714.        23
    ##  4    10016 New York Gramercy Park and …     3731.     3019.      712.         9
    ##  5    10001 New York Chelsea and Clinton     4108.     3398.      710.         4
    ##  6    10002 New York Lower East Side         3645.     2935.      710.        11
    ##  7    10004 New York Lower Manhattan         3150.     2444.      706.        32
    ##  8    10038 New York Lower Manhattan         3573.     2876.      698.        14
    ##  9    10012 New York Greenwich Village …     3629.     2942.      686.        12
    ## 10    10010 New York Gramercy Park and …     3697.     3012.      685.        10

The dataset `rent_drop` was create to compare rental prices in January
2021 to prices in January 2020 for all available ZIP code. It contains
`82` records with valid rental price difference between the two time
points. The variable `rent_drop` stores the calculated difference, while
`rent_rank` represents the rank of rental prices in January 2020.

The dataset `rent_drop_10` lists the 10 ZIP codes with largest drop in
price from January 2020 to 2021. All of them are from `New York` County.
Most of them also ranked among the top rental prices in January 2020
base on `rent_rank`.
